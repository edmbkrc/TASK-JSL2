# RAG Chatbot with Llama & Gemma

This project is a Retrieval-Augmented Generation (RAG) chatbot that uses Llama and Gemma language models to answer user queries based on uploaded documents. The chatbot processes documents, stores them in a vector database, and retrieves relevant information to generate accurate responses.

## Features

- **Document Support**: Upload PDF, DOC, and DOCX files.
- **Retrieval-Augmented Generation**: Combines document retrieval with LLM-based generation for accurate answers.
- **LLM Integration**:
  - **Llama**: A powerful language model for detailed responses.
  - **Gemma**: A concise and precise language model for efficient answers.
- **User Authentication**: Optional authentication for secure access.
- **Persistent Vectorstore**: Dynamically updates vectorstore with new document uploads.


### Prerequisites

Ensure you have the following installed:
- Docker
- Python 3.9+
- [Ollama](https://ollama.ai/) (for Llama-based processing)


### Installation

1. **Clone the Repository**
   ```bash
   git clone https://github.com/edmbkrc/TASK-JSL2.git
   cd TASK-JSL2


